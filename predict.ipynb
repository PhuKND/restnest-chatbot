{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%env MODEL_VERSION=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghBJ0KCx8jv-",
        "outputId": "d94608ba-8c22-4b9e-a9b0-1b6d9be9f094"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: MODEL_VERSION=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cmd to check gpu process\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMRkvNSsULmB",
        "outputId": "1ab5d1b9-b64e-4cf9-990d-16e07dcfc56e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 11 10:40:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HVvkd34hJBuL"
      },
      "outputs": [],
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kC5UIHQhJMbM"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf-models-official==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PGwkTxHNJOFw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prt7l7lQTywk",
        "outputId": "28b87ce9-6965-48cd-8977-85ba0e635936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('../gdrive/MyDrive/bert-chatbot/sample.csv')\n",
        "\n",
        "data = data[data['intent']!='FALLBACK']\n",
        "data = data[data['intent']!='FORBIDDEN']\n",
        "data = data[~data['intent'].str.startswith(\"OTHERS_\")]\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df['intent'])\n",
        "\n",
        "num_of_classes = len(le.classes_)"
      ],
      "metadata": {
        "id": "0wUUV3wbE9Nd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "f = open('../gdrive/MyDrive/bert-chatbot/reply.json')\n",
        "response = json.load(f)\n",
        "print(response['GENDER'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTkGx4LYFMNU",
        "outputId": "36bae236-f47a-4917-ab86-7665146a0306"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'en': \"I don't know my gender yet, but I was created by a male developer.\", 'zh': '我仲未知我係男定女，但我嘅開發者係男人嚟。', 'fr': 'Je ne sais pas encore, mais mon développeur est un homme.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir='/gdrive/MyDrive/bert-chatbot/model/' + os.getenv(\"MODEL_VERSION\") + '/saved_model'\n",
        "\n",
        "reloaded = tf.saved_model.load(model_dir)"
      ],
      "metadata": {
        "id": "zDf2ixYbFWN7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"response language: en\\n\")\n",
        "lang = 'en'\n",
        "query = [\"你好!\", \"hello\", \"琴日入完tqqq 今日即跌\", \"你辦公時間是甚麼?\", \"you perform bad\"]\n",
        "\n",
        "predictions = reloaded(query)\n",
        "\n",
        "for i, pred in enumerate(predictions):\n",
        "  predictedIntent = le.classes_[tf.argmax(pred).numpy()]\n",
        "  print(\"Query: {}\".format(query[i]))\n",
        "  print(\"Response: {} [Intention predicted: {}]\".format(response.get(predictedIntent)[0][lang], predictedIntent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nePgqrBpEmOP",
        "outputId": "6d414022-3f0a-4c51-987d-c1bc106b9ab3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response language: en\n",
            "\n",
            "Query: 你好!\n",
            "Response: Hi, how is your day? [Intention predicted: GREETINGS]\n",
            "Query: hello\n",
            "Response: Hi, how is your day? [Intention predicted: GREETINGS]\n",
            "Query: 琴日入完tqqq 今日即跌\n",
            "Response: I lost a lot on stock, sooner I won't even have money to pay the rent cost on AWS EC2... which means you may not reach me later. [Intention predicted: INVESTMENT]\n",
            "Query: 你辦公時間是甚麼?\n",
            "Response: As long as the server keeps running, I work 7/24. So just reach me anytime you are free. [Intention predicted: OFFICE_HOUR]\n",
            "Query: you perform bad\n",
            "Response: Sorry sorry, I know I am not smart enough. Maybe I will improve in the future with more training data. [Intention predicted: APPRAISAL_BAD]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "185mVda-HeyUI04oI8CfirpXowgQlAVNW",
      "authorship_tag": "ABX9TyNfcFlbz4d76owWvhpeOzxO"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}